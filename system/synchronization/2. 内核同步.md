### 临界区
临界区就是一段代码，其他进程进入临界区前，必须等待已进入临界区的进程执行完临界区中的所有代码。

至于为什么要有临界区，这是因为多个进程有可能交叉访问一些公共资源，最终结果就是会导致数据的不一致现象。因此，内核必须准确的识别出相关的临界区，并实施必要的手段，保证临界区内的资源只能被互斥的访问。

针对单CPU系统，只需简单的禁用内核抢占功能来实现临界区。而针对多CPU系统，我们则需要一些特定的同步技术来实现临界区。

### 同步原语
linux系统下常见的同步原语有如下几种：
```
技术 | 说明 | 使用范围
---- | --- | ----
每CPU变量 | 在CPU之间共享 | 所有CPU
原子操作 |  对一个数据原子操作（读-修改-写） | 所有CPU
内存屏障 | 避免指令重排 | 所有CPU
自旋锁 | 加锁时忙等 | 本地CPU或所有CPU
信号量 | 加锁时阻塞等待（睡眠） | 所有CPU
顺序锁 | 基于访问计数器的锁 | 所有CPU
禁止本地中断 | 禁止单个CPU的本地中断 | 本地CPU
禁止本地软中断 | 禁止单个CPU的本地可延迟函数处理 | 本地CPU
读-拷贝-更新（RCU） | 通过指针来共享数据，而非加锁 | 所有CPU
```

#### 每CPU变量
最直接的同步就是避免数据冲突，也即使用每CPU变量，CPU只能访问自己的元素，而不能访问其他CPU的元素。每CPU变量可以借助内存排列，使其对应不同的缓存行。因为多个CPU同时对一个缓存行进行操作就涉及到数据同步。

一般对每CPU变量的操作需要禁止本地CPU中断和软中断，否则发生进程抢占时，数据会发生冲突。

这种方式一般仅限在内核中使用，用户态下很少用到。

#### 原子操作
假定多个CPU同时对一个变量进行‘读-修改-写’的操作，如果不添加任何防护措施，最终得到的结果将会出乎意料，因为这个过程不是原子操作。

最直接的想法就是添加原子指令，让这个过程变为原子操作，任何这样的操作都必须以单个指令操作，中间不能中断。当然，这需要芯片来保证。

现在，根据这个准则来回顾80x86的指令：
- 进行零次或一次对齐内存访问的汇编指令是原子的
- 如果在读之后、写之前没有其他处理器占用总线，那么“读-更新-写”指令（inc，dec）是原子的。单处理器系统中不会发生内存总线被窃取的情况
- 操作码前缀是lock，那么“读-更新-写”指令也是原子的。当控制单元检测到这个前缀时，就锁定内存总线，指导这条指令执行完毕
- 操作码前缀是rep（0xf2，0xf3）的汇编指令不是原子的。这条指令强制控制单元多次重复执行相同的指令。但是在每次执行前都必须检查挂起的中断

为了使程序员更方便的进行原子操作，linux内核提供了专门的函数和宏，操作对应的atomic_t类型的变量，实现原子操作。如
- atomic_read
- atomic_set
- atomic_add
- ...
注意，所有的原子操作函数或宏，最终都会在生成的汇编语句前添加lock前缀。

#### 优化和内存屏障
现代编译器基本都具备指令重排的能力，指令重排能够极大的加速程序的执行。然而，在处理同步时，如果允许同步语句之后的指令在同步语句之前执行，就会出现不可预料的结果。

优化屏障(optimization barrier)原语保证编译程序不会混淆放在原语之前的指令和放在原语之后的指令。在linux系统中，优化屏障就是barrier()宏，展开就是：
- asm volatile("":::"memory")
	- asm告诉编译器要插入汇编指令
	- volatile关键字禁止编译器将asm中的汇编指令和其他汇编指令组合重排
	- memory关键字强制编译器假定RAM中的所有内存单元都已被修改，也即缓存失效，所有的数据读取都必须访问内存
但是，优化屏障并不保证不是当前CPU把指令混在一起执行，这是内存屏障需要保证的事情。

内存屏障(memory barrier)原语保证，原语之后的指令开始执行之前，原语之前的指令都已经执行完毕。常见的内存屏障场景：
- 对I/O端口进行操作的所有指令
- 由lock前缀的所有指令
- 写控制寄存器、系统寄存器、调试寄存器的所有指令
- 少数汇编语言指令，如iret，终止中断程序或异常程序

linux系统提供了六个内存屏障原语：
- mb()：适用于mp和up的内存屏障
- rmb()：适用于mp和up的读内存屏障
- wmb()：适用于mp和up的写内存屏障
- smp_mb()：适用于mp的内存屏障
- smp_rmb()：适用于mp的读内存屏障
- smp_wmb()：适用于mp的写内存屏障
注意，这些内存屏障也可以被当做优化屏障，因为屏障后的指令不会出现在屏障前面的指令之前。

内存屏障原语的实现依赖于系统体系结构。如果CPU支持lfence指令，就把rmb()宏展开为asm volatile("lfence")，否则就展开为asm volatile("lock; addl $0, 0(%%sp)":::"momory")。asm就是告诉编译器插入一些指令起优化屏障的作用。注意：addl $0, 0(%%sp)就是将0添加到栈顶元素，这条语句没有什么作用，但是因为有lock前缀，这条指令变成一个内存屏障。

Intel上的wmb()宏更简单，它就展开为barrier()，这是因为Intel处理器不对写内存访问进行重新排序。不过，这个宏还是禁止编译器重新组合指令。

回顾一下原子操作，所有的原子操作都具备内存屏障的作用，因为有lock前缀。

#### 自旋锁
共享数据的同步手段，我们最直观的就是加锁。其中，自旋锁就是一种比较特殊的锁：如果内核控制路径发现锁空闲，就获取该锁，并执行对应的操作；如果发现锁已被其他内核控制路径获取，那就忙等待（反复执行一条紧凑的循环之灵，直到锁被释放）。

一般来说，由自旋锁保护的临界区都是禁止抢占的。但是在自旋锁忙等期间，内核抢占还是允许的，也即等待自旋锁的进程可能被更高优先级的进程取代。

在单处理器系统上，自旋锁一般是实现禁止、开启内核抢占，而非起锁的作用。

linux系统下，自旋锁结构spinlock_t结构体包含两个字段：
- slock：表示自旋锁的状态，1表示未加锁，负数和0都表示已加锁
- break_lock：表示进程正在忙等待（仅在内核支持SMP和内核抢占的情况下才会使用）

自旋锁的操作有：
- spin_lock_init()：把自旋锁置位1（未加锁）
- spin_lock()：循环，直到自旋锁为1，然后，把自旋锁置位0
- spin_unlock()：把自旋锁置位1
	- movb $1, slp->slock
- spin_unlock_wait()：等待，直到自旋锁为1
- spin_is_locked()：如果自旋锁为1，返回0，否则返回1
- spin_trylock()：把自旋锁置为0，如果原来其值为1，则返回1，否则返回0

需要注意的是，在抢占内核和非抢占内核中，自旋锁的实现相差很大。主要是因为，在支持抢占内核，获取自旋锁需要关闭中断，如果获取自旋锁失败，需要打开中断，并有可能被更高优先级进程抢占。

#### 读/写自旋锁
读写锁是一种针对特殊场景的优化：读多写少。多个内核控制路径可以同时获取读锁，读同一个数据结构；如果有内核控制路径想要写该数据结构，那么它就必须先获取写锁。

读写自旋锁低层结构是rwlock_t，包含两个字段：
- lock字段，共32位，但分为两部分：
	- 24位计数器（0~23位），并发读操作内核控制路径的数目
	- 锁标记字段（24位），当没有内核控制路径读或写时设置该位，否则清0
- break_lock字段，同spin_lock

如果自旋锁为空（未锁，没有读者），那么lock字段值为0x01000000；如果写者获取自旋锁（锁定，没有读者），那么lock字段值为0x00000000；如果多个读者获取自旋锁，那么lock字段值为0x00ffffff, 0x00fffffe, ...

获取读自旋锁和写自旋锁的步骤与spinlock类似：如果开启了内核抢占，则首先需要禁用内核抢占。然后递减lock字段值（读自旋锁减1，写自旋锁减0x01000000），检测是否获取了对应的自旋锁。如果没有获取自旋锁，然后自旋直到lock字段满足条件，再次尝试获取锁。

而释放读自旋锁和写自旋锁则只需恢复抢锁时减去的值（读自旋锁加1，写自旋锁加0x01000000），然后允许内核抢占。

