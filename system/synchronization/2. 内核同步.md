### 临界区
临界区就是一段代码，其他进程进入临界区前，必须等待已进入临界区的进程执行完临界区中的所有代码。

至于为什么要有临界区，这是因为多个进程有可能交叉访问一些公共资源，最终结果就是会导致数据的不一致现象。因此，内核必须准确的识别出相关的临界区，并实施必要的手段，保证临界区内的资源只能被互斥的访问。

针对单CPU系统，只需简单的禁用内核抢占功能来实现临界区。而针对多CPU系统，我们则需要一些特定的同步技术来实现临界区。

### 同步原语
linux系统下常见的同步原语有如下几种：

技术 | 说明 | 使用范围
---- | --- | ----
每CPU变量 | 在CPU之间共享 | 所有CPU
原子操作 |  对一个数据原子操作（读-修改-写） | 所有CPU
内存屏障 | 避免指令重排 | 所有CPU
自旋锁 | 加锁时忙等 | 本地CPU或所有CPU
信号量 | 加锁时阻塞等待（睡眠） | 所有CPU
顺序锁 | 基于访问计数器的锁 | 所有CPU
禁止本地中断 | 禁止单个CPU的本地中断 | 本地CPU
禁止本地软中断 | 禁止单个CPU的本地可延迟函数处理 | 本地CPU
读-拷贝-更新（RCU） | 通过指针来共享数据，而非加锁 | 所有CPU

#### 每CPU变量
最直接的同步就是避免数据冲突，也即使用每CPU变量，CPU只能访问自己的元素，而不能访问其他CPU的元素。每CPU变量可以借助内存排列，使其对应不同的缓存行。因为多个CPU同时对一个缓存行进行操作就涉及到数据同步。

一般对每CPU变量的操作需要禁止本地CPU中断和软中断，否则发生进程抢占时，数据会发生冲突。

这种方式一般仅限在内核中使用，用户态下很少用到。

#### 原子操作
假定多个CPU同时对一个变量进行‘读-修改-写’的操作，如果不添加任何防护措施，最终得到的结果将会出乎意料，因为这个过程不是原子操作。

最直接的想法就是添加原子指令，让这个过程变为原子操作，任何这样的操作都必须以单个指令操作，中间不能中断。当然，这需要芯片来保证。

现在，根据这个准则来回顾80x86的指令：
- 进行零次或一次对齐内存访问的汇编指令是原子的
- 如果在读之后、写之前没有其他处理器占用总线，那么“读-更新-写”指令（inc，dec）是原子的。单处理器系统中不会发生内存总线被窃取的情况
- 操作码前缀是lock，那么“读-更新-写”指令也是原子的。当控制单元检测到这个前缀时，就锁定内存总线，指导这条指令执行完毕
- 操作码前缀是rep（0xf2，0xf3）的汇编指令不是原子的。这条指令强制控制单元多次重复执行相同的指令。但是在每次执行前都必须检查挂起的中断

为了使程序员更方便的进行原子操作，linux内核提供了专门的函数和宏，操作对应的atomic_t类型的变量，实现原子操作。如
- atomic_read
- atomic_set
- atomic_add
- ...
注意，所有的原子操作函数或宏，最终都会在生成的汇编语句前添加lock前缀。

#### 优化和内存屏障
现代编译器基本都具备指令重排的能力，指令重排能够极大的加速程序的执行。然而，在处理同步时，如果允许同步语句之后的指令在同步语句之前执行，就会出现不可预料的结果。

优化屏障(optimization barrier)原语保证编译程序不会混淆放在原语之前的指令和放在原语之后的指令。在linux系统中，优化屏障就是barrier()宏，展开就是：
- asm volatile("":::"memory")
	- asm告诉编译器要插入汇编指令
	- volatile关键字禁止编译器将asm中的汇编指令和其他汇编指令组合重排
	- memory关键字强制编译器假定RAM中的所有内存单元都已被修改，也即缓存失效，所有的数据读取都必须访问内存
但是，优化屏障并不保证不是当前CPU把指令混在一起执行，这是内存屏障需要保证的事情。

内存屏障(memory barrier)原语保证，原语之后的指令开始执行之前，原语之前的指令都已经执行完毕。常见的内存屏障场景：
- 对I/O端口进行操作的所有指令
- 由lock前缀的所有指令
- 写控制寄存器、系统寄存器、调试寄存器的所有指令
- 少数汇编语言指令，如iret，终止中断程序或异常程序

linux系统提供了六个内存屏障原语：
- mb()：适用于mp和up的内存屏障
- rmb()：适用于mp和up的读内存屏障
- wmb()：适用于mp和up的写内存屏障
- smp_mb()：适用于mp的内存屏障
- smp_rmb()：适用于mp的读内存屏障
- smp_wmb()：适用于mp的写内存屏障
注意，这些内存屏障也可以被当做优化屏障，因为屏障后的指令不会出现在屏障前面的指令之前。

内存屏障原语的实现依赖于系统体系结构。如果CPU支持lfence指令，就把rmb()宏展开为asm volatile("lfence")，否则就展开为asm volatile("lock; addl $0, 0(%%sp)":::"momory")。asm就是告诉编译器插入一些指令起优化屏障的作用。注意：addl $0, 0(%%sp)就是将0添加到栈顶元素，这条语句没有什么作用，但是因为有lock前缀，这条指令变成一个内存屏障。

Intel上的wmb()宏更简单，它就展开为barrier()，这是因为Intel处理器不对写内存访问进行重新排序。不过，这个宏还是禁止编译器重新组合指令。

回顾一下原子操作，所有的原子操作都具备内存屏障的作用，因为有lock前缀。

#### 自旋锁
共享数据的同步手段，我们最直观的就是加锁。其中，自旋锁就是一种比较特殊的锁：如果内核控制路径发现锁空闲，就获取该锁，并执行对应的操作；如果发现锁已被其他内核控制路径获取，那就忙等待（反复执行一条紧凑的循环之灵，直到锁被释放）。

一般来说，由自旋锁保护的临界区都是禁止抢占的。但是在自旋锁忙等期间，内核抢占还是允许的，也即等待自旋锁的进程可能被更高优先级的进程取代。

在单处理器系统上，自旋锁一般是实现禁止、开启内核抢占，而非起锁的作用。

linux系统下，自旋锁结构spinlock_t结构体包含两个字段：
- slock：表示自旋锁的状态，1表示未加锁，负数和0都表示已加锁
- break_lock：表示进程正在忙等待（仅在内核支持SMP和内核抢占的情况下才会使用）

自旋锁的操作有：
- spin_lock_init()：把自旋锁置位1（未加锁）
- spin_lock()：循环，直到自旋锁为1，然后，把自旋锁置位0
- spin_unlock()：把自旋锁置位1
	- movb $1, slp->slock
- spin_unlock_wait()：等待，直到自旋锁为1
- spin_is_locked()：如果自旋锁为1，返回0，否则返回1
- spin_trylock()：把自旋锁置为0，如果原来其值为1，则返回1，否则返回0

需要注意的是，在抢占内核和非抢占内核中，自旋锁的实现相差很大。主要是因为，在支持抢占内核，获取自旋锁需要关闭中断，如果获取自旋锁失败，需要打开中断，并有可能被更高优先级进程抢占。

#### 读/写自旋锁
读写锁是一种针对特殊场景的优化：读多写少。多个内核控制路径可以同时获取读锁，读同一个数据结构；如果有内核控制路径想要写该数据结构，那么它就必须先获取写锁。

读写自旋锁低层结构是rwlock_t，包含两个字段：
- lock字段，共32位，但分为两部分：
	- 24位计数器（0~23位），并发读操作内核控制路径的数目
	- 锁标记字段（24位），当没有内核控制路径读或写时设置该位，否则清0
- break_lock字段，同spin_lock

如果自旋锁为空（未锁，没有读者），那么lock字段值为0x01000000；如果写者获取自旋锁（锁定，没有读者），那么lock字段值为0x00000000；如果多个读者获取自旋锁，那么lock字段值为0x00ffffff, 0x00fffffe, ...

获取读自旋锁和写自旋锁的步骤与spinlock类似：如果开启了内核抢占，则首先需要禁用内核抢占。然后递减lock字段值（读自旋锁减1，写自旋锁减0x01000000），检测是否获取了对应的自旋锁。如果没有获取自旋锁，然后自旋直到lock字段满足条件，再次尝试获取锁。

而释放读自旋锁和写自旋锁则只需恢复抢锁时减去的值（读自旋锁加1，写自旋锁加0x01000000），然后允许内核抢占。

#### 顺序锁
读写自旋锁有个最大的问题，读和写具有相同的优先级，如果当前CPU获取读锁，那么另一个CPU还能够获取读锁，这样就有可能造成写锁永远获取不到。

linux2.6引入了一种顺序锁，它与读写自旋锁非常相似，但是，写锁拥有更高的权限。即使读者正在读时，写者也能够继续运行。其优点就是，写者永远不会等待，但是其缺点也很明显，读者需要反复读取多次直到副本有效。

顺序锁结构体seqlock_t包含两个字段：
- lock字段：同spinlock_t
- sequence字段：顺序计数器，每个读者必须在读数据前后读取两次sequence字段，如果其值不相同，则说明期间有写者更新了计数器，那么读取的数据就是无效的。

当读者进入临界区时，不必禁用内核抢占；而当写者进入临界区时，自动禁用内核抢占。

需要注意的是，并不是所有情况都适合顺序锁的使用场景。一般满足一下条件则可以考虑使用顺序锁：
- 被保护的数据不包括被写者修改和被读者间接引用的指针（防止写者更新指针对读者造成影响）
- 读者的临界区没有副作用（多次效果和一次相同）
- 读者的临界区代码尽量简短，而写者的临界区应该尽量少访问

#### 信号量
从本质上说，信号量实现了一个加锁原语，即让等待者睡眠，直到等到的资源空闲。linux提供两种信号量：
- 内核信号量，由内核控制路径使用
- System V IPC信号量，由用户态进程使用

内核信号量结构体定义如下：
- count：存放atomic_t类型数据。如果大于0，就表示空闲，也即资源可用；如果等于0，表示资源正忙，但是没有进程在等待这个资源；如果小于0，表示资源正忙，并且至少有一个进程在等待该资源。注意count初始值可以是任意正数n，表示最多允许n个进程并发访问该资源
- wait：存放等待队列链表的地址。如果没有进程在等待该资源，则wait为空
- sleepers：标志位，表示是否有进程在信号量上睡眠

#### 读写信号量
读写信号量与读写自旋锁非常类似，但是在信号量再次空闲之前，进程会被挂起而非自旋。

内核控制路径可以为读并发获取读写信号量，但是写必须互斥访问。内核以严格FIFO顺序来处理所有等待读写信号量的所有进程：如果有读者或写者发现信号量关闭，这些进程就被插入到等待队列的队尾，当信号量被释放时，就唤醒等待队列队首进程，如果唤醒的是读者，还会依次检查并唤醒等待队列中的其他读者进程，直到遇到一个写者进程；而如果首次唤醒的是写者进程，等待队列上的其他进程就继续睡眠。

读写信号量结构体rw_semaphore定义如下：
- count：存放两个16位计数器。高16位存放以补码形式存放非等待写者进程的总数（0或1）和等待的写内核控制路径数。而第16位存放非等待的读者和写者的进程总数
- wait_list：指向等待进程的链表。链表中每个元素都是一个rwsem_waiter结构，该结构包含一个指针和一个标志，指针指向睡眠进程的进程描述符，而标志则表示进程是读者还是写者
- wait_lock：自旋锁，用于保护等待对列链表和rw_semaphore结构本身

#### 禁止本地中断
确保一组内核语句被当做一个临界区处理的主要机制就是禁止本地中断，然而本地中断并不保护运行在另一个CPU上的中断处理程序对数据结构的并发访问。因此，多处理器系统上禁止本地中断常常和自旋锁结合使用。

宏local_irq_disable()使用cli汇编语言指令关闭本地中断，宏local_irq_enable()使用sti指令打开本地中断。cli和sti分别清楚和设置eflags控制寄存器的IF标志。

由于中断可以嵌套，因此内核不必知道当前控制路径执行之前IF标志的值，只需保存IF的旧值，并在执行结束时恢复该值。

保存和恢复是由local_irq_save()和local_irq_restore()实现的。local_irq_save()先把eflags寄存器的内容拷贝至一个局部变量中，然后调用cli清零IF；在临界区末尾，调用local_irq_restore()来恢复eflags寄存器的值。

#### 可延迟函数（软中断）
由于软中断总是在硬件中断处理程序结束时执行，因此禁止软中断可以由禁止本地中断来实现。

除此之外，通过操作当前thread_info的preempt_count字段中的软中断计数器，可以在本地激活或禁止软中断。如果软中断计数器是正数，那么do_softirq()就不会执行软中断。宏local_bh_disable()给本地软中断计数器加1，而宏local_bh_enable()为本地软中断计数器减1。

### 同步访问内核结构
系统并发度取决于：
- 同时运转的I/O设备数
- 进行有效工作的CPU数

为了使I/O吞吐量最大化，应该是中断禁止保持很短的时间。因为如果中断被禁止，I/O设备产生的IRQ被忽略，I/O设备将会空闲。

而为了有效的利用CPU，应该尽可能避免使用自旋锁的同步原语。因为它浪费了宝贵的机器周期，同时，自旋锁对高速缓存有不利影响。只要内核路径获取自旋锁，就会禁用本地中断或本地软中断，并禁止内核抢占。

内核控制路径数据结构的保护手段：

访问数据结构的内核控制路径 | 单处理器保护 | 多处理器保护
---- | --- | ----
异常 | 信号量 | 无
中断 | 本地中断禁止 | 自旋锁
可延迟函数 | 无 | 无或自旋锁
异常与中断 | 本地中断禁止 | 自旋锁
异常和可延迟函数 | 本地软中断禁止 | 自旋锁
中断和可延迟函数 | 本地中断禁止 | 自旋锁
异常、中断和可延迟函数 | 本地中断禁止 | 自旋锁
